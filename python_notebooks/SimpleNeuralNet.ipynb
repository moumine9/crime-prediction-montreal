{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Importing essentials libraries\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import collections\n",
    "import datetime\n",
    "import scipy\n",
    "\n",
    "import graphviz\n",
    "import pydot\n",
    "import plotly\n",
    "from plotly.graph_objs import Scatter, Heatmap, Layout\n",
    "plotly.offline.init_notebook_mode(connected=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Essential functions for the code\n",
    "\n",
    "#Funciton for retrieving the factors of a numbers. It's used to optimize the batch size.\n",
    "def get_factors(x):\n",
    "    facts = [] #array that contains the factors.\n",
    "    \n",
    "    for i in range(1, x + 1):\n",
    "        if x % i == 0:\n",
    "            facts.append(i)\n",
    "    \n",
    "    return facts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 93078 entries, 0 to 93077\n",
      "Data columns (total 10 columns):\n",
      "CATEGORIE    93078 non-null int64\n",
      "JOUR         93078 non-null int32\n",
      "QUART        93078 non-null int64\n",
      "PDQ          93078 non-null int64\n",
      "LAT          93078 non-null float64\n",
      "LONG         93078 non-null float64\n",
      "PLACE_ID     93078 non-null int64\n",
      "DATE         93078 non-null datetime64[ns]\n",
      "MOIS         93078 non-null int32\n",
      "ANNEE        93078 non-null int32\n",
      "dtypes: datetime64[ns](1), float64(2), int32(3), int64(4)\n",
      "memory usage: 6.0 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Read dataset file\n",
    "file = pd.read_csv(\"improved_spvm_2015-2018.csv\")\n",
    "\n",
    "#Manipulating the dataset to reflect the usage\n",
    "file[\"DATE\"] =  pd.to_datetime(file['JOUR'], format='%Y-%m-%d') #to transform the column into a datetime type\n",
    "\n",
    "#transform the quart section to numeric (should be 0,1,2 for morning, afternoon and evening)\n",
    "file = file.replace('jour',0)\n",
    "file = file.replace('soir',1)\n",
    "file = file.replace('nuit',2)\n",
    "\n",
    "#split the 'DATE' columns into multiple ones.\n",
    "file['JOUR'] = pd.DatetimeIndex(file['DATE']).day\n",
    "file['MOIS'] = pd.DatetimeIndex(file['DATE']).month\n",
    "file['ANNEE'] = pd.DatetimeIndex(file['DATE']).year\n",
    "\n",
    "#Manipulating the 'CATEGORIE' column to transform it into a numeric\n",
    "values_categories = np.unique(file['CATEGORIE'])\n",
    "file = file.replace(values_categories, np.array([0, 1, 2, 3, 4 ,5])) \n",
    "\n",
    "#quick overview on the file to make sure it has been loaded properly\n",
    "print(file.info())\n",
    "#print(file.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "colorscale": "Viridis",
         "type": "heatmap",
         "x": [
          "CATEGORIE",
          "JOUR",
          "QUART",
          "PDQ",
          "LAT",
          "LONG",
          "PLACE_ID",
          "MOIS",
          "ANNEE"
         ],
         "y": [
          "CATEGORIE",
          "JOUR",
          "QUART",
          "PDQ",
          "LAT",
          "LONG",
          "PLACE_ID",
          "MOIS",
          "ANNEE"
         ],
         "z": [
          [
           1,
           0.003007759227507481,
           -0.005645061460509933,
           -0.01775462092440871,
           0.011198437794532579,
           -0.011190772708521474,
           0.01858783173288127,
           -0.017124984248037028,
           0.023270418922368488
          ],
          [
           0.003007759227507481,
           1,
           -0.00581749344080852,
           0.0025528229926577214,
           -0.0034334035280485374,
           0.0034487062721828953,
           0.0012316892367119834,
           -0.015818404369635348,
           0.005216928699337318
          ],
          [
           -0.005645061460509933,
           -0.00581749344080852,
           1,
           0.004740872604408606,
           0.00042553262872122965,
           -0.0003458617642802065,
           -0.015704461013673607,
           -0.004961853385870579,
           -0.0012177695318557622
          ],
          [
           -0.01775462092440871,
           0.0025528229926577214,
           0.004740872604408606,
           1,
           0.03290431256846565,
           -0.02336315493435443,
           -0.28758020424098885,
           -0.004162102465834812,
           0.008638352822894099
          ],
          [
           0.011198437794532579,
           -0.0034334035280485374,
           0.00042553262872122965,
           0.03290431256846565,
           1,
           -0.9999359037288799,
           0.18323146659235207,
           -0.0038367576956795297,
           -0.009025393437783346
          ],
          [
           -0.011190772708521474,
           0.0034487062721828953,
           -0.0003458617642802065,
           -0.02336315493435443,
           -0.9999359037288799,
           1,
           -0.18663613380804725,
           0.003841232930159661,
           0.009218752333313353
          ],
          [
           0.01858783173288127,
           0.0012316892367119834,
           -0.015704461013673607,
           -0.28758020424098885,
           0.18323146659235207,
           -0.18663613380804725,
           1,
           -0.006964528372079385,
           -0.030826256224761626
          ],
          [
           -0.017124984248037028,
           -0.015818404369635348,
           -0.004961853385870579,
           -0.004162102465834812,
           -0.0038367576956795297,
           0.003841232930159661,
           -0.006964528372079385,
           1,
           -0.18266527844596997
          ],
          [
           0.023270418922368488,
           0.005216928699337318,
           -0.0012177695318557622,
           0.008638352822894099,
           -0.009025393437783346,
           0.009218752333313353,
           -0.030826256224761626,
           -0.18266527844596997,
           1
          ]
         ]
        }
       ],
       "layout": {
        "title": "Correlation values"
       }
      },
      "text/html": [
       "<div id=\"043e0cd6-d38c-48e0-8135-a49a42dfb0bc\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"043e0cd6-d38c-48e0-8135-a49a42dfb0bc\", [{\"type\": \"heatmap\", \"z\": [[1.0, 0.003007759227507481, -0.005645061460509933, -0.01775462092440871, 0.011198437794532579, -0.011190772708521474, 0.01858783173288127, -0.017124984248037028, 0.023270418922368488], [0.003007759227507481, 1.0, -0.00581749344080852, 0.0025528229926577214, -0.0034334035280485374, 0.0034487062721828953, 0.0012316892367119834, -0.015818404369635348, 0.005216928699337318], [-0.005645061460509933, -0.00581749344080852, 1.0, 0.004740872604408606, 0.00042553262872122965, -0.0003458617642802065, -0.015704461013673607, -0.004961853385870579, -0.0012177695318557622], [-0.01775462092440871, 0.0025528229926577214, 0.004740872604408606, 1.0, 0.03290431256846565, -0.02336315493435443, -0.28758020424098885, -0.004162102465834812, 0.008638352822894099], [0.011198437794532579, -0.0034334035280485374, 0.00042553262872122965, 0.03290431256846565, 1.0, -0.9999359037288799, 0.18323146659235207, -0.0038367576956795297, -0.009025393437783346], [-0.011190772708521474, 0.0034487062721828953, -0.0003458617642802065, -0.02336315493435443, -0.9999359037288799, 1.0, -0.18663613380804725, 0.003841232930159661, 0.009218752333313353], [0.01858783173288127, 0.0012316892367119834, -0.015704461013673607, -0.28758020424098885, 0.18323146659235207, -0.18663613380804725, 1.0, -0.006964528372079385, -0.030826256224761626], [-0.017124984248037028, -0.015818404369635348, -0.004961853385870579, -0.004162102465834812, -0.0038367576956795297, 0.003841232930159661, -0.006964528372079385, 1.0, -0.18266527844596997], [0.023270418922368488, 0.005216928699337318, -0.0012177695318557622, 0.008638352822894099, -0.009025393437783346, 0.009218752333313353, -0.030826256224761626, -0.18266527844596997, 1.0]], \"y\": [\"CATEGORIE\", \"JOUR\", \"QUART\", \"PDQ\", \"LAT\", \"LONG\", \"PLACE_ID\", \"MOIS\", \"ANNEE\"], \"x\": [\"CATEGORIE\", \"JOUR\", \"QUART\", \"PDQ\", \"LAT\", \"LONG\", \"PLACE_ID\", \"MOIS\", \"ANNEE\"], \"colorscale\": \"Viridis\"}], {\"title\": \"Correlation values\"}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"043e0cd6-d38c-48e0-8135-a49a42dfb0bc\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"043e0cd6-d38c-48e0-8135-a49a42dfb0bc\", [{\"type\": \"heatmap\", \"z\": [[1.0, 0.003007759227507481, -0.005645061460509933, -0.01775462092440871, 0.011198437794532579, -0.011190772708521474, 0.01858783173288127, -0.017124984248037028, 0.023270418922368488], [0.003007759227507481, 1.0, -0.00581749344080852, 0.0025528229926577214, -0.0034334035280485374, 0.0034487062721828953, 0.0012316892367119834, -0.015818404369635348, 0.005216928699337318], [-0.005645061460509933, -0.00581749344080852, 1.0, 0.004740872604408606, 0.00042553262872122965, -0.0003458617642802065, -0.015704461013673607, -0.004961853385870579, -0.0012177695318557622], [-0.01775462092440871, 0.0025528229926577214, 0.004740872604408606, 1.0, 0.03290431256846565, -0.02336315493435443, -0.28758020424098885, -0.004162102465834812, 0.008638352822894099], [0.011198437794532579, -0.0034334035280485374, 0.00042553262872122965, 0.03290431256846565, 1.0, -0.9999359037288799, 0.18323146659235207, -0.0038367576956795297, -0.009025393437783346], [-0.011190772708521474, 0.0034487062721828953, -0.0003458617642802065, -0.02336315493435443, -0.9999359037288799, 1.0, -0.18663613380804725, 0.003841232930159661, 0.009218752333313353], [0.01858783173288127, 0.0012316892367119834, -0.015704461013673607, -0.28758020424098885, 0.18323146659235207, -0.18663613380804725, 1.0, -0.006964528372079385, -0.030826256224761626], [-0.017124984248037028, -0.015818404369635348, -0.004961853385870579, -0.004162102465834812, -0.0038367576956795297, 0.003841232930159661, -0.006964528372079385, 1.0, -0.18266527844596997], [0.023270418922368488, 0.005216928699337318, -0.0012177695318557622, 0.008638352822894099, -0.009025393437783346, 0.009218752333313353, -0.030826256224761626, -0.18266527844596997, 1.0]], \"y\": [\"CATEGORIE\", \"JOUR\", \"QUART\", \"PDQ\", \"LAT\", \"LONG\", \"PLACE_ID\", \"MOIS\", \"ANNEE\"], \"x\": [\"CATEGORIE\", \"JOUR\", \"QUART\", \"PDQ\", \"LAT\", \"LONG\", \"PLACE_ID\", \"MOIS\", \"ANNEE\"], \"colorscale\": \"Viridis\"}], {\"title\": \"Correlation values\"}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Firsts steps in the analysis : correlation analysis.\n",
    "# In fact, we'll use several features for the SVM but before that, we need to make sure that each fetures\n",
    "df = file\n",
    "\n",
    "donnees = list(df.corr()) #getting the columns names.\n",
    "vals = df.corr().values #getting the computed values for the correlation between each feature.\n",
    "\n",
    "#print(df.corr())\n",
    "\n",
    "plotly.offline.iplot({\n",
    "    \"data\": [Heatmap(z=vals, y=donnees, x=donnees, colorscale='Viridis')],\n",
    "    \"layout\": Layout(title='Correlation values')\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65154, 1, 7)\n",
      "(65154, 1)\n"
     ]
    }
   ],
   "source": [
    "#Building the dataset : 70% training and 30% test set.\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "datas = pd.DataFrame(file, columns=['JOUR', 'QUART', 'LAT', 'LONG', 'PLACE_ID', 'MOIS', 'ANNEE'])\n",
    "values = np.asarray(datas.values,dtype=np.uint8)\n",
    "size = len(datas)\n",
    "x = int(0.70*size)\n",
    "\n",
    "trainset_x = values[0:x]\n",
    "testset_x = values[x+1:-1]\n",
    "\n",
    "values = np.asarray(file['CATEGORIE'],dtype=np.uint8)\n",
    "trainset_y = values[0:x]\n",
    "testset_y = values[x+1:-1]\n",
    "\n",
    "#print(trainset_x.shape)\n",
    "#print(testset_x.shape)\n",
    "#print(trainset_y.shape)\n",
    "#print(testset_y.shape)\n",
    "\n",
    "trainX = np.reshape(trainset_x, (trainset_x.shape[0], 1, trainset_x.shape[1]))\n",
    "trainY = np.reshape(trainset_y, (trainset_y.shape[0],1))\n",
    "\n",
    "testX = np.reshape(testset_x, (testset_y.shape[0], 1, testset_x.shape[1]))\n",
    "testY = np.reshape(testset_y, (testset_y.shape[0],1))\n",
    "\n",
    "print(trainX.shape)\n",
    "print(trainY.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Possible batch size =[1, 2, 3, 6, 10859, 21718, 32577, 65154] \n",
      "\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_10 (Embedding)     (None, None, 1)           65154     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_7 ( (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 6)                 12        \n",
      "=================================================================\n",
      "Total params: 65,166\n",
      "Trainable params: 65,166\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected embedding_10_input to have 2 dimensions, but got array with shape (65154, 1, 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-f1a00d0e8f22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m#model.add(Dense(1, activation='sigmoid'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfactors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    854\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1427\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1428\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1430\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1303\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1305\u001b[0;31m                                     exception_prefix='input')\n\u001b[0m\u001b[1;32m   1306\u001b[0m         y = _standardize_input_data(y, self._feed_output_names,\n\u001b[1;32m   1307\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    125\u001b[0m                                  \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m                                  \u001b[0;34m' dimensions, but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m                                  str(array.shape))\n\u001b[0m\u001b[1;32m    128\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_dim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected embedding_10_input to have 2 dimensions, but got array with shape (65154, 1, 7)"
     ]
    }
   ],
   "source": [
    "#Building the model\n",
    "\n",
    "factors = get_factors(trainX.shape[0])\n",
    "print(\"Possible batch size =\" + str(factors) + \" \\n\\n\" )\n",
    "\n",
    "model = Sequential()\n",
    "model.add(keras.layers.Embedding(trainX.shape[0],1))\n",
    "model.add(keras.layers.GlobalAveragePooling1D())\n",
    "model.add( keras.layers.Dense(len(values_categories), activation=tf.nn.softmax))\n",
    "\n",
    "model.summary() #output model\n",
    "\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#model = Sequential()\n",
    "#model.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
    "#model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "#model.add(MaxPooling1D(pool_size=2))\n",
    "#model.add(LSTM(100))\n",
    "#model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "history = model.fit(trainX, trainY, epochs=30,batch_size=factors[4],verbose=1,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27922/27922 [==============================] - 0s     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Test accuracy: 0.312907384858\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'val_acc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-d5f5d3ce3897>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Plot training & validation accuracy values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'val_acc'"
     ]
    }
   ],
   "source": [
    "#Metrics evaluations + graphics\n",
    "\n",
    "test_loss, test_acc = model.evaluate(testX, testY)\n",
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "#SVG(model_to_dot(model).create(prog='dot', format='svg'))\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['acc'])\n",
    "#plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "#plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "#f1_score(testset_y, predictions, average='macro')  \n",
    "#f1_score(testset_y, predictions, average='micro')  \n",
    "#f1_score(testset_y, predictions, average='weighted')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions here\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
