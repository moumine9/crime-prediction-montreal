{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-79ae6553044c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mActivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "#Importing essentials libraries\n",
    "\n",
    "import csv\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import math\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation, Dropout\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import collections\n",
    "import datetime\n",
    "import scipy\n",
    "\n",
    "import graphviz\n",
    "import pydot\n",
    "import plotly\n",
    "import plotly.plotly as py\n",
    "from plotly.graph_objs import Scatter, Heatmap, Layout\n",
    "plotly.offline.init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Function for building the model\n",
    "\n",
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, look_back=1):\n",
    "  dataX, dataY = [], []\n",
    "  for i in range(len(dataset)-look_back-1):\n",
    "    a = dataset[i:(i+look_back), 0]\n",
    "    dataX.append(a)\n",
    "    dataY.append(dataset[i + look_back, 0])\n",
    "  return numpy.array(dataX), numpy.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Read dataset file\n",
    "file = pandas.read_csv(\"improved_spvm_2015-2019.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Display Dataset to see what we are working on\n",
    "jours = file[\"JOUR\"]\n",
    "jours = list(jours)\n",
    "jours = collections.Counter(jours)\n",
    "\n",
    "jours_x = list(jours.keys())\n",
    "jours_y = list(jours.values())\n",
    "\n",
    "plotly.offline.iplot({\n",
    "    \"data\": [Scatter(x= jours_x, y= jours_y)],\n",
    "    \"layout\": Layout(title=\"Crimes per day\")\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Preparing the dataset : 70% trainset ; 30% test set.\n",
    "\n",
    "#x = int(0.70*len(jours_x))\n",
    "y = int(0.70*len(jours_y))\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "x_train = jours_y[0:y]\n",
    "x_test = jours_y[y+1:-1]\n",
    "\n",
    "X = len(x_train)\n",
    "Y = len(x_test)\n",
    "\n",
    "x_train = numpy.asarray(x_train)\n",
    "x_test = numpy.asarray(x_test)\n",
    "\n",
    "x_train = x_train.reshape(X,1)\n",
    "x_test = x_test.reshape(Y,1)\n",
    "\n",
    "#Nu-Vac\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.fit_transform(x_test)\n",
    "\n",
    "print(\"Preparing dataset finished !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Building the training models\n",
    "\n",
    "look_back = 14 #Numbers of days to look back and feed the model\n",
    "\n",
    "trainX, trainY = create_dataset(x_train, look_back=look_back)\n",
    "testX, testY = create_dataset(x_test, look_back=look_back)\n",
    "\n",
    "trainX = numpy.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "\n",
    "\n",
    "tbCallBack = keras.callbacks.TensorBoard(log_dir='Graph', histogram_freq=0,  \n",
    "          write_graph=True, write_images=True)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(4, input_shape=(1, look_back)))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam',metrics=['mae'])\n",
    "history = model.fit(trainX, trainY, epochs=100, batch_size=14, verbose=0,shuffle=True,callbacks=[tbCallBack])\n",
    "\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Training Metrics\n",
    "\n",
    "# Create traces\n",
    "trace0 = Scatter(\n",
    "    y = history.history['loss'],\n",
    "    mode = 'markers+lines',\n",
    "    name = 'Train'\n",
    ")\n",
    "#trace1 = go.Scatter(\n",
    "#    y = history.history['val_loss'],\n",
    "#    mode = 'markers+lines',\n",
    "#    name = 'Test'\n",
    "#)\n",
    "\n",
    "data = [trace0]\n",
    "\n",
    "plotly.offline.iplot(data, filename='Loss+ValLoss')\n",
    "\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainY = scaler.inverse_transform([trainY])\n",
    "testPredict = scaler.inverse_transform(testPredict)\n",
    "testY = scaler.inverse_transform([testY])\n",
    "\n",
    "trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:, 0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:, 0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Showing Predictions\n",
    "\n",
    "predictions = (scaler.inverse_transform(testPredict)).flatten()\n",
    "normal_vals = (scaler.inverse_transform(x_test)).flatten()\n",
    "normal_vals = normal_vals[14:-1]\n",
    "\n",
    "random_x = jours_x[y+1:-1]\n",
    "\n",
    "\n",
    "# Create traces\n",
    "trace_pred = Scatter(\n",
    "    x = random_x,\n",
    "    y = predictions.tolist(),\n",
    "    mode = 'markers',\n",
    "    name = 'Predictions'\n",
    ")\n",
    "trace_normal = Scatter(\n",
    "    x = random_x,\n",
    "    y = normal_vals.tolist(),\n",
    "    mode = 'markers',\n",
    "    name = 'Actual Values'\n",
    ")\n",
    "\n",
    "data = [trace_pred, trace_normal]\n",
    "\n",
    "plotly.offline.iplot(data, filename='Res')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
